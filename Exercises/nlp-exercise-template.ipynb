{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "6c19d029-25f5-4d8e-9514-bf3ad9d30026",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Agam\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Agam\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Agam\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Agam\\\\Documents\\\\Programming\\\\Repos\\\\Deep-Learning-Alexander\\\\Exercises'"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
    "#find current directory\n",
    "import os\n",
    "import re\n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "0e625f8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Agam\\\\Documents\\\\Programming\\\\Repos\\\\Deep-Learning-Alexander\\\\Exercises'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e2401a-3b28-4a42-ad99-4623e795c5b3",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "f5766eb4-ca56-44be-9c47-23a102b3d3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the directory we are running the cell from:\n",
    "\n",
    "\n",
    "train_df = pd.read_csv('../lab/data/imdb_train_data_small.csv')\n",
    "#test_df = pd.read_csv('../lab/data/imdb_test_data_small.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "6342a5a9-2277-422f-96af-351bad324de7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I rated this a 3. The dubbing was as bad as I ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;br /&gt;&lt;br /&gt;Cheap-looking and ugly, this film ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This film concerns purportedly non-establishme...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ho-hum. An inventor's(Horst Buchholz)deadly bi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Definitely not worth the rental, but if you ca...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  I rated this a 3. The dubbing was as bad as I ...      0\n",
       "1  <br /><br />Cheap-looking and ugly, this film ...      0\n",
       "2  This film concerns purportedly non-establishme...      0\n",
       "3  Ho-hum. An inventor's(Horst Buchholz)deadly bi...      0\n",
       "4  Definitely not worth the rental, but if you ca...      0"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()\n",
    "\n",
    "#train_df.shape\n",
    "\n",
    "#train_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693a8840-336c-4b42-b6b8-2c4cc53f229f",
   "metadata": {},
   "source": [
    "# Tokenization\n",
    "\n",
    "Create your own tokenization algorithm. Remember to handle upper/lower case, comma, punctioation and so on.\n",
    "Each word should hava an integer connected to it. Word as key and integer as value in a dict is one way to do it.\n",
    "\n",
    "Tensorflow have tokenization models, but try to bild it yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "caa2cc1d-9051-4db9-8fc5-a939df97a5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(dataset):\n",
    "    \n",
    "    token_map = {'<UNK>': 0}\n",
    "    reverse_token_map = {0: '<UNK>'}\n",
    "    current_index = 1\n",
    "\n",
    "    # Function to clean and split text into words.\n",
    "    def preprocess(text):\n",
    "        text = text.lower()\n",
    "        text = re.sub(r\"[^\\w\\s]+\", \" \", text)\n",
    "        return text.split()\n",
    "\n",
    "    # Iterate over the rows of the dataset and split the text into words.\n",
    "    for index, row in dataset.iterrows():\n",
    "        words = preprocess(row['text'])\n",
    "        for word in words:\n",
    "            if word not in token_map:\n",
    "                token_map[word] = current_index\n",
    "                reverse_token_map[current_index] = word\n",
    "                current_index += 1\n",
    "\n",
    "    return token_map, reverse_token_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "8c5ba819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<UNK>': 0, 'this': 1, 'is': 2, 'a': 3, 'test': 4, 'another': 5}\n",
      "{0: '<UNK>', 1: 'this', 2: 'is', 3: 'a', 4: 'test', 5: 'another'}\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "dataset = pd.DataFrame({'text': ['This is a test.', 'This is another test.']})\n",
    "token_map, reverse_token_map = tokenize(dataset)\n",
    "print(token_map)\n",
    "print(reverse_token_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2566c0-015a-4cdf-b88d-b41376df220d",
   "metadata": {},
   "source": [
    "# Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "91ff2b32-2e36-4848-8be9-c7e880d3ddac",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "30dd737e-3810-4866-8054-5db39ecddace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "32681497-e3e4-44f1-a335-6fce79310f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "This dataset 25,000 movies reviews IMDB, labeled sentiment (positive/negative). Reviews preprocessed, review encoded list word indexes (integers). For convenience, words indexed overall frequency dataset, instance integer \"3\" encodes 3rd frequent word data. This allows quick filtering operations as: \"only consider top 10,000 common words, eliminate top 20 common words\".\n",
      "372 495\n"
     ]
    }
   ],
   "source": [
    "def remove_stopwords(text):\n",
    "    # Your code\n",
    "    words = text.split()\n",
    "    #Remove stop words\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    #Rejoin words\n",
    "    filtered_text = ' '.join(filtered_words)\n",
    "\n",
    "    return filtered_text\n",
    "text = 'This is a dataset of 25,000 movies reviews from IMDB, labeled by sentiment (positive/negative). Reviews have been preprocessed, and each review is encoded as a list of word indexes (integers). For convenience, words are indexed by overall frequency in the dataset, so that for instance the integer \"3\" encodes the 3rd most frequent word in the data. This allows for quick filtering operations such as: \"only consider the top 10,000 most common words, but eliminate the top 20 most common words\".'\n",
    "filtered_text = remove_stopwords(text)\n",
    "print(type(filtered_text))\n",
    "print(filtered_text)\n",
    "print(len(filtered_text), len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ae56ad-156e-4a0d-be28-d17914bcc475",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "f77df94d-37e1-4615-a8cf-051296763a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ea7ac992-e0c9-4e47-836a-c7a07ee22aa5",
   "metadata": {},
   "source": [
    "lemmatizer.lemmatize('Horse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "82697754-3845-4cbd-8f21-9b8624612c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Instantiate the WordNet lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "#nltk.download('wordnet')\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    pos = tag_dict.get(tag, wordnet.NOUN)\n",
    "    #print(f\"Word: {word}, POS Tag: {pos}\")  # Debugging line\n",
    "    return pos\n",
    "\n",
    "def lemmatize(word):\n",
    "    word = word.lower()\n",
    "    # Lemmatize the word with the appropriate POS tag\n",
    "    lemma = lemmatizer.lemmatize(word, get_wordnet_pos(word))\n",
    "    #print(f\"Original: {word}, Lemmatized: {lemma}\")  # Debugging line\n",
    "    return lemma\n",
    "\n",
    "# Example usage\n",
    "lemmatized_word = lemmatize('Horses')\n",
    "# should be 'Horse'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f0f1fe-e10c-4bc1-8533-b22f7b194f3b",
   "metadata": {},
   "source": [
    "# Word embedding and sentiment analysis model\n",
    "We want to create a model that can say if a movie review is bad or good.\n",
    "\n",
    "- Preprocess the text\n",
    "- Convert text to seqiuence of integers\n",
    "- Create architecture that includes embeddings\n",
    "- Build and train your models\n",
    "- Evaluate preformance\n",
    "\n",
    "Building models from scratch is not something you usually do, but those who would like to dig deeper into the math behind Simple RNN, LSTM and GRU can do it by creating the cells from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "c67861b1-61e9-4b7f-a525-f27c11093338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def pad_data(embedded_text, token_map, max_length):\n",
    "    # All sentences should be of the same lenght, but if a sentence is shorter than the longest, pad it.\n",
    "    # Lowercase, remove stop words, lemmatize\n",
    "    words = embedded_text.lower().split()\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    lemmatized_words = [lemmatize(word) for word in filtered_words]\n",
    "\n",
    "    # Convert words to integers\n",
    "    integer_sequence = [token_map.get(word, token_map['<UNK>']) for word in lemmatized_words]\n",
    "\n",
    "    # Pad the sequence\n",
    "    padded_sequence = tf.keras.preprocessing.sequence.pad_sequences([integer_sequence], maxlen=max_length, padding='post')\n",
    "\n",
    "    return padded_sequence[0]\n",
    "\n",
    "# Example usage\n",
    "text = \"Your example text goes here\"\n",
    "token_map = {\"example\": 1, \"text\": 2, \"<UNK>\": 0}  # Define your token_map here\n",
    "max_length = 20  # Define the maximum length of sequences\n",
    "padded_text = pad_data(text, token_map, max_length)\n",
    "print(padded_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae3425e-214e-4f0d-89fa-dd61faacbda3",
   "metadata": {},
   "source": [
    "## RNN with tensorflow modules\n",
    "[Simple RNN cell](https://www.tensorflow.org/api_docs/python/tf/keras/layers/SimpleRNN)\n",
    "\n",
    "[Embedding](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "ac733a4c-b314-4b2e-ae0d-295e3e2671d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_rnn_model():\n",
    "    inputs = np.random.random([32, 10, 8]).astype(np.float32)\n",
    "    simple_rnn = tf.keras.layers.SimpleRNN(4)\n",
    "    output = simple_rnn(inputs)\n",
    "\n",
    "    simple_rnn = tf.keras.layers.SimpleRNN(\n",
    "        4, return_sequences=True, return_state=True)\n",
    "    whole_seq_output, final_state = simple_rnn(inputs)\n",
    "\n",
    "    print(output.shape)\n",
    "    print(whole_seq_output.shape)\n",
    "    print(final_state.shape)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(1000, 32))\n",
    "    model.add(SimpleRNN(32))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01152d72-7062-4d00-b3f4-7d1ae3b30f3e",
   "metadata": {},
   "source": [
    "## RNN from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "2ba7e11b-131c-49b7-9a3c-0fcd363a632e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNCell(tf.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.Wxh = tf.Variable(tf.random.normal([input_dim, hidden_dim])) # Weight matrix for the input vector x\n",
    "        self.Whh = tf.Variable(tf.random.normal([hidden_dim, hidden_dim]))# weight matrix for the hidden state h\n",
    "        self.bh = tf.Variable(tf.zeros([hidden_dim])) # bias vector\n",
    "\n",
    "    def __call__(self, x, h):\n",
    "        h_next = tf.tanh(tf.matmul(x, self.Wxh) + tf.matmul(h, self.Whh) + self.bh)\n",
    "        return h_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "9177958f-cbe0-466c-b39e-78a87ce4f1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN Model Class\n",
    "class MyRNNModel(tf.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim=1, sequence_length=20):\n",
    "        super().__init__()\n",
    "        self.sequence_length = sequence_length\n",
    "        self.embedding = Embedding(vocab_size, embedding_dim) # Embedding layer\n",
    "        self.rnn_cell = RNNCell(embedding_dim, hidden_dim) # RNN cell\n",
    "        self.Why = tf.Variable(tf.random.normal([hidden_dim, output_dim])) # Weight matrix to map the hidden state to the output dimension\n",
    "        self.by = tf.Variable(tf.zeros([output_dim]))\n",
    "\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = self.embedding(x)\n",
    "        h = tf.zeros([x.shape[0], self.rnn_cell.Whh.shape[0]])\n",
    "\n",
    "        # Process the input sequence\n",
    "        for t in range(self.sequence_length):\n",
    "            x_t = x[:, t, :]\n",
    "            h = self.rnn_cell(x_t, h)\n",
    "\n",
    "        y = tf.matmul(h, self.Why) + self.by\n",
    "        return tf.sigmoid(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "5433047d-199f-4aab-858c-f4e25bba4550",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, inputs, targets):\n",
    "    loss_function = tf.keras.losses.BinaryCrossentropy()\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    clip_norm = 1.0\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs)\n",
    "        loss = loss_function(targets, predictions)\n",
    "        # Calculate gradients\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "\n",
    "    # Apply gradient clipping\n",
    "    clipped_gradients, _ = tf.clip_by_global_norm(gradients, clip_norm)\n",
    "    optimizer.apply_gradients(zip(clipped_gradients, model.trainable_variables))\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "2ececbef-f1f6-4d36-97ee-42ce80b3ff95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 2.5289, Accuracy: 0.5729\n",
      "Epoch 2/5, Loss: 3.6321, Accuracy: 0.5728\n",
      "Epoch 3/5, Loss: 3.2666, Accuracy: 0.5376\n",
      "Epoch 4/5, Loss: 1.4073, Accuracy: 0.5493\n",
      "Epoch 5/5, Loss: 1.7778, Accuracy: 0.5880\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "padded_train_data = np.array([pad_data(text, token_map, max_length) for text in train_df['text']])\n",
    "batch_size = 32\n",
    "NUM_EPOCHS = 5\n",
    "model = MyRNNModel(len(token_map), 32, 32)\n",
    "calculate_accuracy = tf.keras.metrics.BinaryAccuracy()\n",
    "y = train_df['label'].values\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((padded_train_data, y)).batch(batch_size)\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    epoch_loss = 0\n",
    "    epoch_accuracy = 0\n",
    "    total_batches = 0\n",
    "\n",
    "    for batch_inputs, batch_targets in train_dataset:\n",
    "        loss = train_step(model, batch_inputs, batch_targets)\n",
    "        epoch_loss += loss.numpy()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        predictions = model(batch_inputs)\n",
    "        accuracy = calculate_accuracy(batch_targets, predictions)\n",
    "        epoch_accuracy += accuracy.numpy()\n",
    "\n",
    "        total_batches += 1\n",
    "\n",
    "    avg_loss = epoch_loss / total_batches\n",
    "    avg_accuracy = epoch_accuracy / total_batches\n",
    "    print(f'Epoch {epoch+1}/{NUM_EPOCHS}, Loss: {avg_loss:.4f}, Accuracy: {avg_accuracy:.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe11f54b-f41a-4f5a-b1f4-5c5390d9bb6a",
   "metadata": {},
   "source": [
    "## LSTM\n",
    "\n",
    "[LSTM Cell](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTMCell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "f4902ef9-520c-4975-9aff-f89b623104e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_model():\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198898ec-771e-4b89-b6dc-12944f0c6d19",
   "metadata": {},
   "source": [
    "## LSTM from scrtch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "9c3a92a1-e930-41c5-8625-4b6c32adf328",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1194722719.py, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[164], line 9\u001b[1;36m\u001b[0m\n\u001b[1;33m    self.Wi =\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# LSTM Cell Class\n",
    "class LSTMCell(tf.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # Gates: input, forget, cell, output\n",
    "        self.Wi =\n",
    "        self.Wf =\n",
    "        self.Wc =\n",
    "        self.Wo =\n",
    "        self.bi =\n",
    "        self.bf =\n",
    "        self.bc =\n",
    "        self.bo =\n",
    "\n",
    "    def __call__(self, x, h, c):\n",
    "        combined = tf.concat([x, h], 1)\n",
    "\n",
    "        i = \n",
    "        f = \n",
    "        o = \n",
    "        c_ = \n",
    "\n",
    "        c_new = \n",
    "        h_new =\n",
    "\n",
    "        return h_new, c_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40f3545-5a8f-45d7-813e-075ae61dd09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Model Class\n",
    "class MyLSTMModel(tf.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.embedding =\n",
    "        self.lstm_cell = LSTMCell(embedding_dim, hidden_dim)\n",
    "        self.Why =\n",
    "        self.by =\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x =\n",
    "        h =\n",
    "        c =\n",
    "\n",
    "        for t in range(sequence_length):\n",
    "            x_t = x[:, t, :]\n",
    "            h, c = self.lstm_cell(x_t, h, c)\n",
    "\n",
    "        y =\n",
    "        return tf.sigmoid(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d248f5-0b90-42f7-99ce-351167d00b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, inputs, targets):\n",
    "    clip_norm = 1.0\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs)\n",
    "        loss = loss_function(targets, predictions)\n",
    "        \n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    clipped_gradients = [tf.clip_by_norm(g, clip_norm) for g in gradients]\n",
    "    optimizer.apply_gradients(model.trainable_variables)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9d6d6e-48d0-4b40-b402-f81b13b62c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((padded_train_data, y)).batch(batch_size)\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    epoch_loss = 0\n",
    "    epoch_accuracy = 0\n",
    "    total_batches = 0\n",
    "\n",
    "    for batch_inputs, batch_targets in train_dataset:\n",
    "        loss = train_step(model, batch_inputs, batch_targets)\n",
    "        epoch_loss += loss.numpy()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        predictions = model(batch_inputs)\n",
    "        accuracy = calculate_accuracy(batch_targets, predictions)\n",
    "        epoch_accuracy += accuracy.numpy()\n",
    "\n",
    "        total_batches += 1\n",
    "\n",
    "    avg_loss = epoch_loss / total_batches\n",
    "    avg_accuracy = epoch_accuracy / total_batches\n",
    "    print(f'Epoch {epoch+1}/{NUM_EPOCHS}, Loss: {avg_loss:.4f}, Accuracy: {avg_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a3810e-0ae8-4058-b749-799b254f3e81",
   "metadata": {},
   "source": [
    "## GRU\n",
    "[GRU Cell](https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRUCell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da681b6-0ae3-4459-87f4-c8184009ea8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_gru_model():\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a06ce2-4f0e-4fb8-b42a-d307982da693",
   "metadata": {},
   "source": [
    "## GRU from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aae6a39-8185-4260-9d6b-e1bb45d2b93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRU Cell Class\n",
    "class GRUCell(tf.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # Update gate parameters\n",
    "        self.Wz =\n",
    "        self.bz =\n",
    "\n",
    "        # Reset gate parameters\n",
    "        self.Wr =\n",
    "        self.br =\n",
    "\n",
    "        # Candidate hidden state parameters\n",
    "        self.Wh =\n",
    "        self.bh =\n",
    "        \n",
    "    def __call__(self, x, h):\n",
    "        combined = tf.concat([x, h], 1)\n",
    "\n",
    "        # Update gate\n",
    "        z =\n",
    "\n",
    "        # Reset gate\n",
    "        r =\n",
    "\n",
    "        # Candidate hidden state\n",
    "        combined_reset =\n",
    "        h_candidate =\n",
    "\n",
    "        # New hidden state\n",
    "        h_new =\n",
    "\n",
    "        return h_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7b6bb3-7353-4aa4-ab88-bf008934661d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRU Model Class\n",
    "class MyGRUModel(tf.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.embedding =\n",
    "        self.gru_cell =\n",
    "        self.Why =\n",
    "        self.by =\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x =\n",
    "        h =\n",
    "\n",
    "        for t in range(sequence_length):\n",
    "            x_t = x[:, t, :]\n",
    "            h = self.gru_cell(x_t, h)\n",
    "\n",
    "        y =\n",
    "        return tf.sigmoid(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5653c0e5-4d7c-443a-9bce-566c92fcac26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, inputs, targets):\n",
    "    clip_norm = 1.0\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs)\n",
    "        loss = loss_function(targets, predictions)\n",
    "        \n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(model.trainable_variables)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b3eae4-cda1-4574-bc05-43869b94fc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((padded_train_data, y)).batch(batch_size)\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    epoch_loss = 0\n",
    "    epoch_accuracy = 0\n",
    "    total_batches = 0\n",
    "\n",
    "    for batch_inputs, batch_targets in train_dataset:\n",
    "        loss = train_step(model, batch_inputs, batch_targets)\n",
    "        epoch_loss += loss.numpy()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        predictions = model(batch_inputs)\n",
    "        accuracy = calculate_accuracy(batch_targets, predictions)\n",
    "        epoch_accuracy += accuracy.numpy()\n",
    "\n",
    "        total_batches += 1\n",
    "\n",
    "    avg_loss = epoch_loss / total_batches\n",
    "    avg_accuracy = epoch_accuracy / total_batches\n",
    "    print(f'Epoch {epoch+1}/{NUM_EPOCHS}, Loss: {avg_loss:.4f}, Accuracy: {avg_accuracy:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
